# ==============================================
# LangChain + Ollama enrichment configuration
# These options are read by scripts in projects/project-5
# ==============================================

# OLLAMA model configuration
# - Name of the local model served by `ollama serve`
# - Examples: llama3.1, mistral, qwen2.5, phi3, etc.
OLLAMA_MODEL=qwen3:32b

# Sampling temperature (0.0–1.0). Lower = more deterministic outputs.
OLLAMA_TEMPERATURE=0.2

# Reference glossary injection (BFO/CCO) — lightweight RAG context
# How to include BFO/CCO reference terms in the prompt:
#   off      -> do not include any reference context
#   full     -> include (truncated) full glossary once in the system prompt
#   retrieve -> per row, select top‑K entries via simple token overlap
#   fuzzy    -> per row, select top‑K entries using RapidFuzz (recommended)
REFERENCE_MODE=fuzzy

# Number of reference entries to inject per row (for retrieve/fuzzy modes)
REF_TOP_K=5

# Max characters of injected reference context to keep prompts compact
REF_MAX_CHARS=4000

# Fuzzy retrieval (RapidFuzz) — used only when REFERENCE_MODE=fuzzy
# Scorer options:
#   token_set_ratio  -> robust to extra/missing words (default)
#   token_sort_ratio -> robust to word order changes
#   wratio           -> overall smart scorer
REF_FUZZY_SCORER=token_set_ratio

# Cutoff score (0–100). Higher = stricter matching, fewer references.
REF_FUZZY_CUTOFF=70

# Post-processing: enforce capitalization of overlapping glossary labels
# If true, after generation we will replace case-insensitive matches of retrieved
# BFO/CCO labels in the output with their canonical casing. This guarantees
# capitalization on overlapping word combinations.
# Options: true|false (1/0/yes/no/on/off supported)
ENFORCE_LABEL_CASING=true

# Note: File paths are fixed in the script and do not need .env entries:
# - INPUT_FILE:   projects/project-5/data/definitions.csv
# - OUTPUT_FILE:  projects/project-5/data/definitions_enriched.csv
# - BFO_CCO_TERMS: projects/project-5/data/bfo_cco_terms.csv

# ==============================================
# ROBOT + ELK reasoning configuration
# ==============================================

# Path to the ROBOT executable; if installed system-wide, keep as 'robot'.
# You may also point to a local wrapper script (e.g., projects/project-4/assignment/robot/robot)
ROBOT_BIN=robot

# Reasoner to use with ROBOT's reason command (default: ELK)
ELK_REASONER=ELK

# Default input ontology for reasoning (can be overridden at CLI)
# Relative to the project-5 directory when used by scripts/reason_with_elk.sh
ELK_INPUT=src/InformationEntityOntology.ttl

# Default output path for reasoned ontology
ELK_OUTPUT=src/module_reasoned.ttl

# Optional Java memory settings for ROBOT, uncomment to set
# ROBOT_JAVA_ARGS=-Xms2G -Xmx4G

# Optional: control ROBOT auto-download in reason_with_elk.sh
# If ROBOT is not found on PATH and ROBOT_BIN doesn't exist, the script will
# download robot.jar to ROBOT_DIR and create a wrapper at ROBOT_BIN (or
# ${ROBOT_DIR}/robot if ROBOT_BIN is just a name).
 ROBOT_VERSION=1.9.7
 ROBOT_DIR=robot


 # ==============================================
 # ROBOT diff configuration (used by scripts/diff_with_robot.sh)
 # ==============================================

 # Left and right files for diff (defaults target the IEO example in this project)
 # Relative to the project-5 directory
 DIFF_LEFT=src/InformationEntityOntology.ttl
 DIFF_RIGHT=src/module_reasoned.ttl

 # Output format for robot diff: md|html|owl|json (see ROBOT docs)
 DIFF_FORMAT=md

 # Output path
 DIFF_OUTPUT=reports/elk_diff.md
